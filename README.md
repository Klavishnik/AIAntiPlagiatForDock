# AIAntiPlagiatForDock

Рекомендовано работать в контейнере, но не обязательно. 
Запускаем скрипт сборки и настройки окружения.
Зависимости ставятся в вирутальные переменные.
``` 
sudo ./install.sh
source venv/bin/activate
```

После этого рядом с приглашением ввода оболочки должно появится ` venv `

```
venv root#
```

Теперь можно использовать скрипты. 

Самый важный скрипт - **all.py**.

Ему передается целевая папка ` target_dir `, где лежат файлы формата .doc(x), которые нужно проверить.

Также через опцию ` -o ` указываем название файла, куда будут писаться логи.

Два необязательных, но важных аргумента, которыми выбираем, какой моделью будут проверяться документы.
* ` -gpt2 `           - https://openai-openai-detector.hf.space/ 

* ` -classificator `  - https://platform.openai.com/ai-text-classifier

*В процессе работы исходные документы будут делиться на куски по 300 (gpt2) - 800 (классификатор) слов и последовательно загружаться на системы.*
*Немного может влиять на точность*

Для использования рекомендована **classificator**, поскольку выше точность и скрость. 
Для её использования нужно получить ключ авторизации от open.ai и изменить переменную  **bearer_token** (строка 16)
Как это сделать смотррите тут
https://github.com/promptslab/openai-detector

Пример запуска
```
python all.py -gpt2 -classificator -o out.txt target_dir/
```
Такой запуск будет содержать ошибки о неудачных попытках отправки данных на сайт. 
Если хотите их избежать или перенаправить в файл, используйте поток ошибок

Пример запуска
```
python all.py -gpt2 -classificator -o out.txt target_dir/ 2> /dev/null
```

## От автора

Ввиду ограничений в работе веб сайтов весть файл скормить им не получается. 
Приходится делить на небольшие куски и загружать отдельно. 
Поэтому для каждого такого "куска" выводится отдельная статистика, а в конце считается среднее по всем кусочкам.

Итак, в логах сначала выводится имя файла, который был обработан.
Далее идет вывод режимов работы:


Сначала `ChatGPT2` - у него низкая точность и долгое время работы из-за не очень хорошего сайта.
Ее вывод такой:
 ``` File: 0, Fake probability: 96.5% ```
Где  ` File `  - номер кусочка файла, а ` Fake probability `:  - вероятность того, что текст сгенерирован. Эти значения даны в процентах, чем больше, тем хуже.

После загрузки всех кусков файла, программа делает подсчет среднего значения по всем файлам -  ` avg_fake_probability: 92.7% ` 
Также есть отладочная информация в виде переменной ` not_loaded_files: ` - в ней написано сколько кусочков не удалось загрузить. Этот параметр влияет на точность

Далее идет  вывод ` AI Text Classifier `
Для кусочков документа у него два параметра:
 ` Pprobability: 9.039683710252689 `  - это вероятность того, что текст сгенерирован.  Значения даны, как СЫРЫЕ ДАННЫЕ. Больше - хуже.
Вторая переменная самая интересная: ` Class:  ` - это  классификация полученных данных. 

Видимо классификатор по значению и каким-то своим параметрам приравнивает значения к определенному классу. 

Классы, которые мне попадались:

``` very unlikely (50>),  unlikely(50-88), unclear if it is(97<), possibly(98<), likely  (99<) ```
Приоритетной информацией является именно параметр классификации. 

Далее считается среднее значение ``` ---> Average fake probability: 18.2% ``` 

Если это значение превышает порог 75, то появляется предупреждение о **ВОЗМОЖНОЙ ГЕНЕРАЦИИ ТЕКСТА ИИ**

Выглядит так: ```  AI generation possible ```

Если это значение превышает порог 96, то оно **ОДНОЗНАЧНО СГЕНЕРИРОВАНО ИИ**

Предупреждение выглядит так: ``` ---> AI GENERATE! ``` 

Скорее всего придется смотреть на текст разбитый по кусочкам. Значение должно "гулять" в процессе. 
Основной ориентир, конечно, классификатор.
